{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the fourth GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "IMG_H, IMG_W = 224, 224\n",
    "BUFFER_SIZE = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = \"../Comp4/task1/data/\"\n",
    "PATH_CKPTS = \"../Comp4/task1/ckpts/3_aug/\"\n",
    "checkpoint_name = \"3_aug\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARGIN_C = 1.2\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_p = 0.9\n",
    "\n",
    "up_down_flip_p = 0.25\n",
    "left_right_flip_p = 0.5\n",
    "rot_p = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_answer(text):\n",
    "    assert len(text) <= 9\n",
    "    \n",
    "    if len(text) == 9:\n",
    "        return text\n",
    "    \n",
    "    need_char = 9 - len(text)\n",
    "    return (\"0\" * need_char) + text\n",
    "\n",
    "def get_q_a(folder, is_get_answer):\n",
    "    tr_q = np.genfromtxt(PATH_TO_DATA + folder + \"q.csv\", delimiter=',').astype(np.int32).astype(str)\n",
    "\n",
    "    tr_target = tr_q[:,0]\n",
    "    tr_target = np.expand_dims(tr_target, 1)\n",
    "    tr_target = np.repeat(tr_target, 9, axis=1)\n",
    "\n",
    "    tr_candidate = tr_q[:,1:]\n",
    "\n",
    "    if is_get_answer:\n",
    "        tr_a = np.genfromtxt(PATH_TO_DATA + folder + \"a.csv\", delimiter=',').astype(np.int32).astype(str)    \n",
    "        ans = []\n",
    "        for i in range(tr_a.shape[0]):\n",
    "            ans.append(list(impute_answer(tr_a[i, 1])))\n",
    "\n",
    "        ans = np.asarray(ans).astype(np.int32)\n",
    "        \n",
    "        return tr_target, tr_candidate, ans\n",
    "    else:\n",
    "        return tr_target, tr_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def image_preprocess(folder, img_name):\n",
    "    img = tf.io.read_file(PATH_TO_DATA + folder + img_name + \".png\")\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img.set_shape([IMG_H, IMG_W, 3])\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    \n",
    "    # img = tf.image.resize(img, size=[64, 64])\n",
    "    \n",
    "    ## VGG\n",
    "#     img = img[...,::-1]\n",
    "#     img -= (103.939, 116.779, 123.68)\n",
    "    \n",
    "    img = img / 255\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def random_flip(image):\n",
    "    up_down_outcome = tf.random.uniform([1], 0, 1)\n",
    "    right_left_outcome = tf.random.uniform([1], 0, 1)\n",
    "\n",
    "    if up_down_outcome<up_down_flip_p:\n",
    "        image = tf.image.flip_up_down(image)\n",
    "\n",
    "    if right_left_outcome<left_right_flip_p:\n",
    "        image = tf.image.flip_left_right(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "@tf.function\n",
    "def random_rot90(image):\n",
    "    prob = tf.random.uniform([1],0,1)\n",
    "    \n",
    "    if prob < (rot_p/2):\n",
    "        image = tf.image.rot90(image)\n",
    "    elif (prob >= (rot_p/2)) and (prob < rot_p):\n",
    "        image = tf.image.rot90(image, k=2)   \n",
    "        \n",
    "    return image\n",
    "\n",
    "@tf.function\n",
    "def image_augmentation(img):\n",
    "    aug_sample = tf.random.uniform([1],0,1)\n",
    "    \n",
    "    if aug_sample < aug_p:\n",
    "        img = random_flip(img)\n",
    "        img = random_rot90(img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_target, tr_candidate, tr_ans = get_q_a(\"s1_train/\", is_get_answer=True)\n",
    "val_target, val_candidate, val_ans = get_q_a(\"s1_valid/\", is_get_answer=True)\n",
    "te_target, te_candidate = get_q_a(\"s1_test/\", is_get_answer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ds_train_generator(object):\n",
    "    def __init__(self, target, candidate, answer, ds_folder):\n",
    "        self.target = target[:, 0]\n",
    "        self.candidate = candidate\n",
    "        self.answer = answer\n",
    "        self.ds_folder = ds_folder\n",
    "        \n",
    "    def preprocessing(self, target, candidate, answer):\n",
    "        img_target = image_preprocess(self.ds_folder, target)\n",
    "        \n",
    "        qq = tf.random.uniform((), 0, 9)\n",
    "        sample_idx = tf.cast(qq, tf.int32)\n",
    "        sampled_candidate = tf.gather(candidate, sample_idx, axis=0)\n",
    "        sampled_answer = tf.gather(answer, sample_idx, axis=0)\n",
    "        \n",
    "        img_candidate = image_preprocess(self.ds_folder, sampled_candidate)\n",
    "        answer = tf.cast(sampled_answer, tf.float32)\n",
    "        \n",
    "        img_target = image_augmentation(img_target)\n",
    "        img_candidate = image_augmentation(img_candidate)\n",
    "        \n",
    "        return img_target, img_candidate, answer\n",
    "        \n",
    "    def generate(self):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((self.target,\n",
    "                                                      self.candidate,\n",
    "                                                      self.answer))\n",
    "        dataset = dataset.map(self.preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "        dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ds_test_generator(object):\n",
    "    def __init__(self, target, candidate, ds_folder):\n",
    "        self.target = target.flatten()\n",
    "        self.candidate = candidate.flatten()\n",
    "        self.ds_folder = ds_folder\n",
    "        \n",
    "    def preprocessing(self, target, candidate):\n",
    "        img_target = image_preprocess(self.ds_folder, target)\n",
    "        img_candidate = image_preprocess(self.ds_folder, candidate)\n",
    "        \n",
    "        return img_target, img_candidate\n",
    "        \n",
    "    def generate(self):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((self.target, self.candidate))\n",
    "        dataset = dataset.map(self.preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        dataset = dataset.batch(BATCH_SIZE)\n",
    "        dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_gen = ds_train_generator(tr_target, tr_candidate, tr_ans, \"s1_train_image/\")\n",
    "ds_train = ds_train_gen.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_valid_gen = ds_test_generator(val_target, val_candidate, \"s1_valid_image/\")\n",
    "ds_valid = ds_valid_gen.generate()\n",
    "\n",
    "ds_test_gen = ds_test_generator(te_target, te_candidate, \"s1_test_image/\")\n",
    "ds_test = ds_test_gen.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_trained_model = tf.keras.applications.vgg16.VGG16(include_top=False,\n",
    "#                                                       weights='imagenet',\n",
    "#                                                       input_shape=(IMG_H, IMG_W, 3))\n",
    "# pre_trained_model.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class siamese_net(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(siamese_net, self).__init__()\n",
    "        self.df_dim = 64\n",
    "        self.t_dim = 128\n",
    "        \n",
    "        self.net_h0_conv2d = tf.keras.layers.Conv2D(self.df_dim, 4, 2, padding='SAME',use_bias=True,\n",
    "                                                    kernel_initializer= tf.random_normal_initializer(stddev=0.02))\n",
    "        self.net_h1_conv2d = tf.keras.layers.Conv2D(self.df_dim*2, 4, 2, padding='SAME',use_bias=True,\n",
    "                                                    kernel_initializer= tf.random_normal_initializer(stddev=0.02))\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.net_h2_conv2d = tf.keras.layers.Conv2D(self.df_dim*4, 4, 2, padding='SAME',use_bias=True,\n",
    "                                                    kernel_initializer= tf.random_normal_initializer(stddev=0.02))\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.net_h3_conv2d = tf.keras.layers.Conv2D(self.df_dim*8, 4, 2, padding='SAME',use_bias=True,\n",
    "                                                    kernel_initializer= tf.random_normal_initializer(stddev=0.02))\n",
    "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.net_h4_flat = tf.keras.layers.Flatten()\n",
    "        self.net_h4_fc = tf.keras.layers.Dense(self.t_dim, use_bias=False,\n",
    "                                               kernel_initializer= tf.random_normal_initializer(stddev=0.02))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        net_h0 = self.net_h0_conv2d(inputs)\n",
    "        net_h0 = tf.nn.leaky_relu(net_h0)\n",
    "        \n",
    "        net_h1 = self.net_h1_conv2d(net_h0)\n",
    "        net_h1 = self.bn1(net_h1)\n",
    "        net_h1 = tf.nn.leaky_relu(net_h1)\n",
    "\n",
    "        net_h2 = self.net_h2_conv2d(net_h1)\n",
    "        net_h2 = self.bn2(net_h2)\n",
    "        net_h2 = tf.nn.leaky_relu(net_h2)\n",
    "\n",
    "        net_h3 = self.net_h3_conv2d(net_h2)\n",
    "        net_h3 = self.bn3(net_h3)\n",
    "        net_h3 = tf.nn.leaky_relu(net_h3)\n",
    "\n",
    "        net_h4 = self.net_h4_flat(net_h3)\n",
    "        net_h4 = self.net_h4_fc(net_h4)\n",
    "\n",
    "        outputs = net_h4\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    cost = tf.reduce_sum(tf.multiply(v1, v2), 1) / (tf.sqrt(tf.reduce_sum(tf.multiply(v1, v1), 1)) * tf.sqrt(tf.reduce_sum(tf.multiply(v2, v2), 1)))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def contrastive_loss(target, candidate, answer):\n",
    "    distance = tf.sqrt(2 - 2 * cosine_similarity(target, candidate))\n",
    "    # distance = tf.sqrt(tf.reduce_sum((target - candidate)**2, 1, keepdims=True))\n",
    "    similarity = answer * tf.square(distance)\n",
    "    dissimilarity = (1-answer) * tf.square(tf.maximum((MARGIN_C - distance), 0))\n",
    "    return tf.reduce_mean(similarity + dissimilarity)\n",
    "\n",
    "@tf.function\n",
    "def cosine_loss(target, candidate, answer):\n",
    "    cosine = tf.keras.losses.cosine_similarity(target, candidate)\n",
    "    output = (answer * cosine) + ((1-answer) * (cosine * (-1)))\n",
    "    \n",
    "    return tf.reduce_mean(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIAMESE = siamese_net()\n",
    "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume training from epoch 0\n"
     ]
    }
   ],
   "source": [
    "last_ckp = tf.train.latest_checkpoint(PATH_CKPTS)\n",
    "start_epoch = 0\n",
    "\n",
    "if last_ckp:\n",
    "    ckpt = tf.train.Checkpoint(optimizer=optimizer, SIAMESE=SIAMESE)\n",
    "    ckpt.restore(last_ckp)\n",
    "    start_epoch = int(last_ckp.split(\"-\")[-1])\n",
    "\n",
    "print(f'Resume training from epoch {start_epoch}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(optimizer=optimizer, SIAMESE=SIAMESE)\n",
    "\n",
    "manager = tf.train.CheckpointManager(ckpt, PATH_CKPTS, max_to_keep=5,\n",
    "                                     checkpoint_name=checkpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(target, candidate, answer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        target_output = SIAMESE(target)\n",
    "        candidate_output = SIAMESE(candidate)\n",
    "        loss = contrastive_loss(target_output, candidate_output, answer)\n",
    "        # loss = cosine_loss(target_output, candidate_output, answer)\n",
    "    \n",
    "    grads = tape.gradient(loss, SIAMESE.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, SIAMESE.trainable_variables))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Loss: 0.10989287495613098\n",
      "Time for epoch 1 is 193.53955507278442 sec\n",
      "\n",
      "Epoch: 2\n",
      "Loss: 0.05015730485320091\n",
      "Time for epoch 2 is 187.05856704711914 sec\n",
      "\n",
      "Epoch: 3\n",
      "Loss: 0.04012462496757507\n",
      "Time for epoch 3 is 187.52709531784058 sec\n",
      "\n",
      "Epoch: 4\n",
      "Loss: 0.0329037681221962\n",
      "Time for epoch 4 is 187.55547642707825 sec\n",
      "\n",
      "Epoch: 5\n",
      "Loss: 0.028901416808366776\n",
      "Time for epoch 5 is 186.61831212043762 sec\n",
      "\n",
      "Epoch: 6\n",
      "Loss: 0.02668379247188568\n",
      "Time for epoch 6 is 188.37966227531433 sec\n",
      "\n",
      "Epoch: 7\n",
      "Loss: 0.024142103269696236\n",
      "Time for epoch 7 is 188.29816675186157 sec\n",
      "\n",
      "Epoch: 8\n",
      "Loss: 0.022261200472712517\n",
      "Time for epoch 8 is 188.2290997505188 sec\n",
      "\n",
      "Epoch: 9\n",
      "Loss: 0.020029980689287186\n",
      "Time for epoch 9 is 188.30143547058105 sec\n",
      "\n",
      "Epoch: 10\n",
      "Loss: 0.019409852102398872\n",
      "Time for epoch 10 is 187.4641354084015 sec\n",
      "\n",
      "Epoch: 11\n"
     ]
    }
   ],
   "source": [
    "loss_hist = []\n",
    "\n",
    "for i in range(start_epoch, EPOCHS):\n",
    "    epoch = i + 1\n",
    "    total_loss = []\n",
    "    start = time.time()\n",
    "    \n",
    "    print(\"Epoch:\", epoch)\n",
    "    \n",
    "    for tar, can, ans in ds_train:\n",
    "        tmp_loss = train_step(tar, can, ans)\n",
    "        # print(\"Current loss: {}\".format(tmp_loss),end=\"\\r\")\n",
    "        total_loss.append(tmp_loss)\n",
    "        \n",
    "    print(\"Contrastive Loss: {}\".format(np.mean(total_loss)))\n",
    "    print('Time for epoch {} is {} sec\\n'.format(epoch, time.time()-start))\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        manager.save(checkpoint_number=epoch)\n",
    "        \n",
    "    loss_hist.append(np.mean(total_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validatoin and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume training from epoch 100\n"
     ]
    }
   ],
   "source": [
    "last_ckp = PATH_CKPTS + \"3_aug-100\" # tf.train.latest_checkpoint(PATH_CKPTS)\n",
    "start_epoch = 0\n",
    "\n",
    "if last_ckp:\n",
    "    ckpt = tf.train.Checkpoint(optimizer=optimizer, SIAMESE=SIAMESE)\n",
    "    ckpt.restore(last_ckp)\n",
    "    start_epoch = int(last_ckp.split(\"-\")[-1])\n",
    "\n",
    "print(f'Resume training from epoch {start_epoch}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(target, candidate):\n",
    "    target_output = SIAMESE(target)\n",
    "    candidate_output = SIAMESE(candidate)\n",
    "    \n",
    "    return cosine_similarity(target_output, candidate_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataset):\n",
    "    out = []\n",
    "\n",
    "    for t, c in dataset:\n",
    "        curr = test_step(t, c)\n",
    "        out.extend(curr.numpy().tolist())\n",
    "        \n",
    "    out = np.asarray(out)\n",
    "    out = np.reshape(out, (-1,9))\n",
    "    \n",
    "    return out\n",
    "\n",
    "def cut_thres(y_pred, thres):\n",
    "    y_pred = (y_pred > thres).astype(np.int32)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "def convert_to_int(y):\n",
    "    output = []\n",
    "    y = y.astype(str).tolist()\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        output.append(int(\"\".join(y[i])))\n",
    "        \n",
    "    return output\n",
    "\n",
    "def convert_to_output(y):\n",
    "    output = []\n",
    "    y = y.astype(str).tolist()\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        output.append(\"\".join(y[i]))\n",
    "        \n",
    "    return output\n",
    "\n",
    "def cal_acc(y_true, y_pred):\n",
    "    output = []\n",
    "    y_true = convert_to_int(y_true)\n",
    "    y_pred = convert_to_int(y_pred)\n",
    "    \n",
    "    for i in range(len(y_true)):\n",
    "        is_same = (y_true[i] == y_pred[i])\n",
    "        output.append(int(is_same))\n",
    "        \n",
    "    return sum(output)/len(output)\n",
    "\n",
    "def output(pred):\n",
    "    pred = convert_to_output(pred)\n",
    "    \n",
    "    output = pd.DataFrame({\"id\": range(len(pred)),\n",
    "                           \"Category\": pred})\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = test(ds_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "COSINE_THRE = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc:  0.997265625\n"
     ]
    }
   ],
   "source": [
    "val_pred_thres = cut_thres(val_pred, COSINE_THRE)\n",
    "val_acc = cal_acc(val_ans, val_pred_thres)\n",
    "print(\"Validation Acc: \", val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_pred = test(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_pred_thres = cut_thres(te_pred, COSINE_THRE)\n",
    "output_df = output(te_pred_thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv(\"../output/{}_{}.csv\".format(checkpoint_name, start_epoch), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
